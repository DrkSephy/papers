\documentclass{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{courier}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{listings}
\usepackage[margin=1in]{geometry}

\title{AlphaGo: Breakthrough in Machine Learning?}
\begin{document}
\nocite{*}


\begin{titlepage}
    \begin{center}
        \vspace*{2.5cm}
        {\bf Master's Thesis}
        
        \vspace*{0.5cm}
        City College of New York
        
        \vspace*{2.5cm}
        
        \vspace{2.5cm}        
        
        \textbf{David Leonard}
	
	\vspace{0.5cm} 
	Date: May 2, 2016
        
        \vspace{1in}
        \vfill
        
    \end{center}
\end{titlepage}

\tableofcontents

\newpage

\section {Introduction}

In the past year at the City College of New York, the Computer Science program has become immensely crowded - particularly the introductory computer science courses. Overcrowding of introductory classes leads to less feedback from Professors at a particularly vulnerable time for new students in which feedback is crucial for understanding the material. On the other hand, in the current generation of software engineering, learning how to use Version Control Systems (VCS) has become an absolute and necessary skill  for all students studying computer science to learn. With these two points in mind, how can we leverage VCS to help alleviate the problem of providing feedback to students while at the same time teaching students how to successfully collaborate together? We will explore both of these ideas in this paper and provide a technical solution to address these problems.

\section {Version Control Systems}

In Software Engineering, we are faced with one common problem - how does a group of individuals successfully collaborate on a project while sharing one codebase? Using a VCS, we can achieve precisely that. Currently, there are two well-known VCS: \footnote{Git: https://git-scm.com/} git and \footnote{Mercurial: https://www.mercurial-scm.org/} mercurial. These tools allow developers to collaborate on a group of files in a \textbf{project} while solving problems such as \textbf{communication} and \textbf{merge conflicts} between files. These projects are stored as \textbf{repositories} in the \textbf{cloud} through the use of \textbf{collaborative platforms} which are \footnote{Github: https://github.com/} and \footnote{Bitbucket: https://bitbucket.org/}. These platforms provide a service which allows developers to communicate, collaborate and control their codebase history. In this paper we will focus exclusively on using git repositories on Bitbucket.

\section{Benefits of VCS}

One common thing that students tend to do when working on software projects is to collaborate with other students. This allows them to learn from each other while at the same time having someone to bounce ideas off of in hopes of being able to solve their own problems. Since students already collaborate verbally with each other in class, one idea to handling overcrowding in classes would be to group students together. By having closely knit groups, students can learn from one another while at the same time being able to finish their numerous programming assignments. 

As beneficial as VCS are, they are often neglected throughout the computer science curriculum. While they are often viewed as tools for software engineering in the real world, they have numerous benefits to students and professors alike. In the upcoming sections we explore the features of VCS and the Bitbucket platform that students can use to their advantage,

\subsection{Version Control}

The keywords in VCS are \textbf{version control}, which in this context means to have the ability to have \textbf{multiple versions} of an existing codebase. Suppose that a student is working on a programming assignment and continuously \textbf{commits} code into the repository, but at a certain point checks in code which breaks existing tests in the assignment. Through the power of \emph{git}, the student can simply \textbf{roll back} their codebase to a previous commit at which everything was functioning properly. 

The power of version control really shines in group projects, as students will regularly break existing code. Even if students commit code which breaks the entire codebase, it can be reverted back to a previous commit in which everything was working fine. Moreover, students can directly place comments at any line of code in the codebase if they have questions about how something works. By adopting this approach, students are able to learn more in-depth from one another as opposed to just grabbing code from elsewhere without properly dissecting it.

\begin{figure}[h!]
\includegraphics[height=10cm, width=16cm]{commit}
\caption{A sample commit}
\centering
\end{figure}

\newpage 


\subsection{Issue Tracking}

Bitbucket features a rich \textbf{issue tracker}, which allows individuals to create tickets detailing any bugs or features that need to be added to a project. The issue tracker can be utilized by creating a separate ticket for each feature that needs to be implemented in a given project:

\begin{figure}[h!]
\centering
\includegraphics[height=4cm, width=14cm]{tracker}
\caption{A sample commit}
\end{figure}

As seen in Figure 2, additional labels may be added to an issue which show the status of the issue as well as the priority and assignee. By creating issues for all required features and distributing them amongst all group members, students can effectively split up a project in such a way that they can pick and choose which features they are comfortable with implementing. This approach helps to build the confidence in a student and ideally allows them to understand how other pieces of the program come together to form one coherent application. Additionally, issues may be closed directly by referencing them through commit messages:

\begin{figure}[h!]
\centering
\includegraphics[height=2cm, width=14cm]{fix}
\caption{Resolving Issues directly through Commits}
\end{figure}

This promotes clean and real-world software engineering practices, while 
teaching students how to effectively maintain a real codebase on a smaller scale. Another approach to using issue trackers is to cycle issues around to other group members should an individual gets stuck with a particular feature - this is to help meet deadlines while also encouraging students to not give up and instead try their hand on another aspect of the program.

\subsection {Best Practices}

Students of all levels learn in their own personal way, and no two ways of thinking will always be the same. This is apparent when asking a student to implement a function which sums up all numbers in an array - two different approaches might be to use a \emph{for} loop while another approach will use a \emph{while} loop. In this case, neither approach is wrong or right, it is up to the student to decide. But what happens when students are given functions to implement which are more sophisticated? A professor will notice that students differ in:

\begin{itemize}
	\item {\textbf{Indentation}}: Students may indent with 2 or 4 spaces, or in the \emph{worst} case, left-justify everything.
	\item {\textbf{Non-descriptive Variable Names}}: Students may not use variable names which are descriptive, hence leading to confusion in the future.
	\item {\textbf{Comments}}: Students may not comment their code, which will cause problems in the future when reviewing for exams.
\end{itemize}

When working alone, students often do not gain insight as to how they may improve their skills or write readable code - a skill that has direct consequences when pursuing a career in software engineering. The best known way to remedy this is to read the source code of others, whether it be online, through peers or to read various programming books. In this model, students collaborating using VCS can observe how their peers write their own code and learn the best practices which work for them and overall get exposed to different ways of thinking.

\section {Project Types}

With the benefits of VCS covered, we now need to explore how students should appropriately create issue tickets for each feature which is needed in a given programming assignment. To do this, we explore various programming assignment formats.

\subsection {Project Skeletons}

A common format for giving students programming assignments is through the use of \textbf{project skeletons}, which consists of empty functions that are documented with comments regarding their implementations. In this scenario, it is trivial to create issues on Bitbucket for these assignments - every function which needs to be implemented will have a corresponding issue. To take things a step further, students can then assign these issues to themselves or other members in the group and add labels to functions which are blockers - meaning that their implementation is needed for other functions. In this sense, it allows students of all programming levels to effectively reason about their projects and to consider how to prioritize their implementation.

\subsection {Requirement Documents}

In higher level classes, sample code through project skeletons are often not given. In these situations, students are presented with documents which state the feature requirements that an application must satisfy. Despite this, it is not always clear what path a project should take when started. Should a base class be built first, or helper functions? By having an issue tracker, students are encouraged to sit down and properly think about the project and break it down into smaller, more manageable chunks. Moreover, students will gain deeper insight as to why \emph{feature x} should come before \emph{feature y} and in turn will have an easier time with their assignment. 

Overall, discussing projects at this granular level promotes a deeper understanding of what needs to be done. Often times students are thinking only about the end result and skip over the finer details, but this type of structured planning will save hours (if not days) of work. With the collaboration model fleshed out, we move onto our next problem - how can students properly be evaluated for any type of group project?

\section {Collaboration Evaluation}

The goal of collaboration is to have groups of students which effectively contribute to a group project. However, in a class full of students (and multiple sections), it becomes nearly impossible for a Professor to properly evaluate everyone fairly. In fact, it is hard enough to effectively determine if students have completed individual projects on their own. What about classes in which an individual's contributions to a group project determines their final grade? These are all difficult problems to solve in the classroom settings, however they become attainable through the use of version control. This brings us to the main focal point of the paper - implementing a tool which can effectively visualize contributions of individuals to a group project.

\subsection {Metrics}

As we have seen in Section 3, version control systems provide us with the ability to track issues and commits. However, we are not limited to these metrics alone - there are various other parameters which are readily made available to us:

\begin {itemize}
	\item {\textbf{Lines of Code}}: How many lines of code did each student contribute to the project? This can be attributed to how much work has gone into their implementations.
	\item {\textbf{Commit Comments}}: How many comments on individual commits did each student create? These can be attributed to a student's curiosity and willingness to understand the codebase.
	\item {\textbf{Issue Comments}}: How many comments on feature issues did each student make? These are attributed to meaningful discussion of features, links to helpful resources and suggestions from other members.
	\item {\textbf{Issues Closed}}: How many issues were closed by each student? These correlate to how many features were implemented by each individual student.
\end {itemize}

Individually, these parameters are not particularly useful nor do they properly demonstrate the performance of a student. However, putting them all together will paint a meaningful and convincing story regarding the lifespan of a project as well as allowing Professors to understand how students are performing. We begin by describing the collection of these parameters for a given project. 

\subsection {Bitbucket API}

Gathering the data needed for a given project is too tedious to be done by hand, however Bitbucket provides an \textbf{Application Program Interface (API)} which allows us to programmatically query data for a given project. An API is simply a web server which understands HTTP requests and responds with data from it's database corresponding to the query parameters it has received. For example, the viewing the url https://api.bitbucket.org/2.0/repositories/DrkSephy/wombat/commits/master?page=1 in any browser will respond with data corresponding to the commits in the repository \emph{wombat} belonging to the user \emph{DrkSephy}. 

\newpage

A subset of the output may be found below:

\begin{figure}[h!]
\centering
\includegraphics[height=6cm, width=14cm]{api}
\caption{Sample Data returned by Bitbucket API}
\end{figure}

Here, we can see various data regarding \emph{commits} in the repository named \emph{wombat}. Among this data, we can see every commit that has occurred along with the user who created the commit as well as the timestamp that it was created/updated. Using various other API endpoints, we can gather all of the necessary data to create an interactive visualization tool. However, we must discuss limitations of accessing data through the Bitbucket API.

\subsection {Privacy and Authentication}

A repository on Bitbucket may be set to \emph{public} (any user can view the contents of the repository), or \emph{private} in which nobody except the users given access to the repository may view its contents. Private repositories allow students to work in safety that no other individual can access their repository and view their code, preventing copying, cheating or other malicious intentions. However, accessing data from private repositories via the Bitbucket API requires a mechanism known as \textbf{\emph{authentication}}, in which an application goes through a protocol to access protected resources. Bitbucket relies on \textbf{OAuth 2.0}, which is a protocol for successfully authenticating a client application with Bitbucket's server for accessing protected resources. The following steps are required for gaining access to these resources:

\begin {enumerate}
	\item Create an OAuth consumer, which is our application in this case. 
	\item Using a given \textbf{secret key}, the consumer makes an HTTP request to get an authorization code.	
	\item Server (Bitbucket Server) issues an \textbf{Authorization Code}.
	\item Consumer redirects the user to Bitbucket's login page using the Authorization code.
	\item Resource owner (Bitbucket) grants access to the consumer (our application).
	\item Server accepts / rejects the user authorization.
	\item Consumer requests an \textbf{Access Token}.
	\item Server responds with the \textbf{Access Token}.
	\item Consumer can now access protected resources using this access token.
	\item The server responds with the protected resource.
\end {enumerate}

\begin{figure}[h!]
\centering
\includegraphics[height=13cm, width=14cm]{oauth}
\caption{OAuth 2.0 Protocol}
\end{figure}

\newpage 

At the end of this entire protocol, steps 9 and 10 repeat until the access token expires. Once an access token expires, the consumer must refresh their token by re-negotiating with the server to gain a new access token.

\section {Application Architecture}

An important decision in our project is to properly choose the tools that are needed to handle the tasks required. In this section we explain the problems and decisions that went into deciding our architecture, which can be seen in Figure 6.

\begin{figure}[h!]
\centering
\includegraphics[height=3cm, width=14cm]{arch}
\caption{Application Architecture}
\end{figure}

\newpage

The most important aspect of this project will be it's performance, both on the client-side and server-side. We begin by discussing performance of the client-side, with respect to rendering data to the client (web browser).

\subsection {React.js}

Given a class of 100 students with groups consisting of roughly 4\~ 5 students, a Professor will have to visualize data for 20\~25 projects. As such, we will find ourselves rendering various data components which need to be efficient over time. Rendering data on the web browser requires modifying the \textbf{Document Object Model (DOM)} tree, which represents the layout of a web page. 

\begin{figure}[h!]
\centering
\includegraphics[height=8cm, width=14cm]{dom}
\caption{Document Object Model Tree}
\end{figure}

In terms of efficiency, updating the DOM tree consists of completely re-writing the tree from scratch. When updating the tree with new data and elements, this becomes costly in terms of node updates and rendering. Luckily, Facebook has released a cutting-edge library called \textbf{React} which is used for building sleek and efficient User Interfaces. React's power is it's ability to update the DOM tree in $\mathcal{O}(n)$ through it's efficient diffing algorithm. Instead of thrashing the entire DOM tree and rebuilding it from scratch, React computes a shadow DOM which shows the change in nodes from the actual DOM, and uses this to update the actual DOM by replacing/removing any nodes which have been marked for update. This problem, known as \textbf{reconciliation of the DOM} is asymptotically an $\mathcal{O}(n^3)$ problem that has been transformed to $\mathcal{O}(n)$ asymptotically.

At a high level, React's reconciliation works by using hand-crafted heuristics which help to predict which parts of the DOM tree are more likely to be updated. In our application, we will often find ourselves updating visualizations and datasets which will benefit from this efficient algorithm, which in turn will allow us to build a highly responsive user interface.

\newpage

\begin{figure}[h!]
\centering
\includegraphics[height=11cm, width=14cm]{reconciliation}
\caption{Reconciliation of the Document Object Model Tree}
\end{figure}

\subsection {Node.js}

Now that our client-side technology stack has been decided, we move to our server-side. The server will have the following tasks:

\begin {itemize}
	\item {\textbf{Authentication Flow}}: The server will be needed for negotiating with Bitbucket to gain access tokens.	
	\item {\textbf{Re-negotiating Access Tokens}}: When a user's access token has expired, the server will need to automatically re-negotiate for an access token.
	\item \textbf{Fetching Resources}: The server will be responsible for fetching all data through queries on the client-side application.
	\item {\textbf{Communication with the database}}: Whenever new data arrives, the server will communicate with the database in order to store responses.
\end {itemize}

The server also needs to be able to handle \textbf{concurrent requests} without blocking the main execution thread. Hence, we choose \textbf{Node} - an efficient and well-tested server-side implementation written in JavaScript. In fact, Node is optimized to use the V8 runtime, which is the fastest JavaScript rendering engine. With these features, we can asynchronously handle hundreds of requests to Bitbucket's server in order to fetch all of the data needed for our application in parallel.

\subsubsection {Security Concerns}

As we previously mentioned, a server is needed for handling Authentication Flow and re-negotiating access tokens. The reason for this is that is has been shown that pure client-side authentication flows are vulnerable to various JavaScript attacks which can intercept and tamper with the request. Moreover, what does the client-side application do with the access token that is received after negotiating with the resource server? One solution is to store the token inside the browser through the use of a \textbf{cookie}, however this cookie is not secure and can be extracted using malicious JavaScript which in turn would lead to the application being compromised. 

In order to solve this problem, using a server to handle our negotiation will lead to our application being secure from these malicious attacks. Lastly, we use the server to communicate with the database for storing user access tokens.

\subsection {Express.js}

In order to handle all of our API requests, we use \textbf{Express} which is an HTTP framework that is built on top of Node. This will allow us to send concurrent HTTP requests to the Bitbucket API which in turn will respond with the data we need to process. Express allows us to define simple HTTP routes, some of which are shown below:
\newline 

\begin{lstlisting}[frame=single]
/**
 * GET /api/count
 * Returns the number of commits in a repository.
*/
app.get('/api/count', isAuthenticated, (req, res) => {
  getJSON('resource_url', req.user.authToken)
  .then((data) => {
    res.send(data);
  });
});
\end{lstlisting}

\vspace{0.5cm} 

\begin{lstlisting}[frame=single]
/**
 * GET /api/issues
 * Returns issue data for a given repository.
*/
app.get('/api/issues', isAuthenticated, (req, res) => {
  getJSON('resource_url', req.user.authToken)
  .then((results) => {
    let parsedData = [];
    results['issues'].forEach((issue) => {
      let issueData = {};
      issueData.reported_by = issue.reported_by.username;
      issueData.title = issue.title;
      if (issue.responsible) {
        issueData.responsible = issue.responsible.username;
      }
      issueData.priority = issue.priority;
      issueData.metadata = issue.metadata.kind;
      issueData.id = generateRandomNumber();
      parsedData.push(issueData);
    });
    res.send(parsedData);
  });
});
\end{lstlisting}

\newpage

\subsection {MongoDB}

The last component of our architecture is the database. In this application, we are primarily dealing with \textbf{JavaScript Object Notation (JSON)} - a lightweight response format returned from HTTP requests. Our data flow consists of the client-side application sending queries to the server, which in turn will respond with JSON data. This JSON is parsed and sent back to the client for rendering, and is also needs to be stored in the database for \textbf{caching} these web responses. JSON data consists of arbitrary key/value pairs, which makes it difficult to create schemas to store our data. As such, we use \textbf{MongoDB} - a document-based database which works very well with JSON data.

\subsubsection {Caching}

While the browser does a good job of caching repeated HTTP requests, we can speed up the turnaround from the client to the server and back by storing the parsed JSON on the server inside of the database. In this setup, whenever the client makes an HTTP request to the server, the server will first check if this data is already stored within the database - if not, the server queries the new data and updates the database and the client. Otherwise, the JSON is returned directly from the database and the client will update.

\subsection {Architecture Summary}

As we have described, we have an efficient pipeline ranging from client-side DOM rendering to concurrent HTTP requests on the server tied together seamlessly using MongoDB - all operating on a lightweight response format (JSON). In turn, we will be able to deliver a fast experience to the end-user which will consist of both Professors and Students. 

\section {Application Features}

With our architecture decided, we move onto describing all of the features of our application. The end goal of this application is to give the viewer a high level understanding of the level of progress in a project. We also want students to be able to get immediate feedback as to how they are performing in a group project.

\subsection {Authentication}

When the user loads the application, they need to be able to authenticate with Bitbucket easily with one click. As stated, this is needed so that they can access any private repositories which they own. In order to implement the OAuth 2.0 protocol on the sever, we use a package called \textbf{passport.js}, which securely implements this protocol and allows us to fetch access tokens. Once the user is successfully authenticated with OAuth, they are redirected to the dashboard. 

\subsection {Subscription Manager}

In order to generate visualizations for a project, the user needs a way to specify which repository they would like to process. We create a subscription manager component which displays all of the repositories which the authenticated user has read access to, shown in Figure 9. 

\begin{figure}[h!]
\centering
\includegraphics[height=6cm, width=17cm]{sub}
\caption{Subscription Manager}
\end{figure}

\newpage

Here the user may quickly subscribe/unsubscribe to any of their repositories with the click of a button. While this is convenient for the user, it may be slow if they have many repositories to scroll through. To circumvent this, we have also created an alternative subscription manager shown in Figure 10 which allows the user to subscribe to a repository given a known repository name and Bitbucket username.

\begin{figure}[h!]
\centering
\includegraphics[height=3cm, width=17cm]{alt}
\caption{Alternate Subscription Manager}
\end{figure}

Once the user subscribes to a repository, the navigation bar will update with the list of subscribed repositories, shown in Figure 11.

\begin{figure}[h!]
\centering
\includegraphics[height=4cm, width=17cm]{update}
\caption{Navigation Bar Updates}
\end{figure}

Clicking one of the items in the navigation bar will take the user into the visualization of the clicked repository name, which we discuss next.

\subsection {Repository Visualization}

The repository visualization consists of the following data components:

\begin {itemize}
	\item \textbf{Commits Card}: Displays the number of commits over a given time frame, along with a sparkling chart detailing the data trend.
	\item \textbf{Issues Opened}: Displays the number of issues opened over a given time frame, along with a sparkline chart detailing the data trend.
	\item \textbf{Issues Assigned}: Displays the number of issues assigned over a given time frame, along with a sparkline chart detailing the data trend.
	\item \textbf{Issues Closed}: Displays the number of issues closed over a given time frame, along with a sparkling chart detailing the data trend.
	\item \textbf{Repository Statistics}: Displays the totals of commits, issues opened/closed/assigned/comments and pull requests throughout the entire repository over the course of time.
	\item \textbf{Time Series}: Displays the commits over a one week for the given repository.
\end {itemize}

We break down their functionality over the course of the next sections.

\subsubsection {Data Cards}

The goal of the \textbf{commits}, \textbf{issues opened}, \textbf{issues closed} and the \textbf{issues assigned} cards is to give an overview of these datasets over a specified time.

\begin{figure}[h!]
\centering
\includegraphics[height=4cm, width=17cm]{cards}
\caption{Data Cards}
\end{figure}

These parameters show arguably the most telling stories of the given repositories. Commits show that the repository is active, while the number of issues opened, assigned and closed demonstrate that features are being thought up and implemented throughout the given time frame. This data is further visualized through the underlying \textbf{sparkling charts}. Moreover, users can use the date range picker in the top left to specify a time range to 

\newpage

\begin{thebibliography}{9}
\bibitem{latexcompanion} 
David Silver et. al.
\textit{Mastering the game of Go with deep neural networks and tree search}. 
(doi:10.1038/nature16961) January 28, 2016.
 
 
\bibitem{einstein} 
Campbell, M., Hoane, A,  Hsu, F.
\textit{Deep Blue}.
Artif. Intell. 134, 57Ð83 (2002).
 
 
\bibitem{einstein} 
Google Research Blog
\textit{What we learned in Seoul with AlphaGo}.
https://goo.gl/bTT19m March 16, 2016.

\end{thebibliography}

\end{document}
